{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2 # type: ignore\n",
    "from sentence_transformers import SentenceTransformer, util # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RepositoryNotFoundError",
     "evalue": "401 Client Error. (Request ID: Root=1-6452d37f-18b6ac3b3616a3cf67665413)\n\nRepository Not Found for url: https://huggingface.co/api/models/sentence-transformers/msmarco-distilroberta-base-v3.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:259\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 259\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[0;32m    260\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/sentence-transformers/msmarco-distilroberta-base-v3",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m SentenceTransformer(\u001b[39m'\u001b[39;49m\u001b[39mmsmarco-distilroberta-base-v3\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:87\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     83\u001b[0m     model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cache_folder, model_name_or_path\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m     86\u001b[0m         \u001b[39m# Download from hub with caching\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[0;32m     88\u001b[0m                             cache_dir\u001b[39m=\u001b[39;49mcache_folder,\n\u001b[0;32m     89\u001b[0m                             library_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msentence-transformers\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     90\u001b[0m                             library_version\u001b[39m=\u001b[39;49m__version__,\n\u001b[0;32m     91\u001b[0m                             ignore_files\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mflax_model.msgpack\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrust_model.ot\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtf_model.h5\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     92\u001b[0m                             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token)\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):    \u001b[39m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_sbert_model(model_path)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\util.py:442\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files, use_auth_token)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39melif\u001b[39;00m use_auth_token:\n\u001b[0;32m    440\u001b[0m     token \u001b[39m=\u001b[39m HfFolder\u001b[39m.\u001b[39mget_token()\n\u001b[1;32m--> 442\u001b[0m model_info \u001b[39m=\u001b[39m _api\u001b[39m.\u001b[39;49mmodel_info(repo_id\u001b[39m=\u001b[39;49mrepo_id, revision\u001b[39m=\u001b[39;49mrevision, token\u001b[39m=\u001b[39;49mtoken)\n\u001b[0;32m    444\u001b[0m storage_folder \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m    445\u001b[0m     cache_dir, repo_id\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    446\u001b[0m )\n\u001b[0;32m    448\u001b[0m all_files \u001b[39m=\u001b[39m model_info\u001b[39m.\u001b[39msiblings\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    118\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\hf_api.py:1604\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[1;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[0;32m   1602\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mblobs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1603\u001b[0m r \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39mget(path, headers\u001b[39m=\u001b[39mheaders, timeout\u001b[39m=\u001b[39mtimeout, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m-> 1604\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   1605\u001b[0m d \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n\u001b[0;32m   1606\u001b[0m \u001b[39mreturn\u001b[39;00m ModelInfo(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39md)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:291\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39melif\u001b[39;00m error_code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRepoNotFound\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[0;32m    278\u001b[0m     \u001b[39m# 401 is misleading as it is returned for:\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     \u001b[39m#    - private and gated repos if user is not authenticated\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[39m#    - missing repos\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[39m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[39m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[0;32m    284\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m make sure you are authenticated.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m     )\n\u001b[1;32m--> 291\u001b[0m     \u001b[39mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m400\u001b[39m:\n\u001b[0;32m    294\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[0;32m    295\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mBad request for \u001b[39m\u001b[39m{\u001b[39;00mendpoint_name\u001b[39m}\u001b[39;00m\u001b[39m endpoint:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m endpoint_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mBad request:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    296\u001b[0m     )\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6452d37f-18b6ac3b3616a3cf67665413)\n\nRepository Not Found for url: https://huggingface.co/api/models/sentence-transformers/msmarco-distilroberta-base-v3.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password."
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('msmarco-distilroberta-base-v3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tags Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_categories(categories):\n",
    "    tags = [tag.strip() for tag in ast.literal_eval(categories)]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'arxiv-paper-abstracts\\arxiv_data_210930-054931.csv')\n",
    "categories = pd.DataFrame(list(df['terms'].unique()),columns=['categories'])\n",
    "categories['clean_categories'] = categories['categories'].apply(clean_categories)\n",
    "tags = set()\n",
    "for index, row in categories.iterrows():\n",
    "    categories = row['clean_categories']\n",
    "    for category in categories:\n",
    "        tags.add(category)\n",
    "tags_df = pd.DataFrame(list(tags), columns=['tags'])\n",
    "tags = set()\n",
    "for index, row in tags_df.iterrows():\n",
    "    categories_str = row['tags']\n",
    "    categories_list = [category.strip() for category in categories_str.replace(',', ';').split(';')]\n",
    "    for category in categories_list:\n",
    "        tags.add(category)\n",
    "tags_df = pd.DataFrame(list(tags), columns=['tags'])\n",
    "tags = set()\n",
    "for index, row in tags_df.iterrows():\n",
    "    categories_str = row['tags']\n",
    "    categories_list = [category.strip() for category in categories_str.replace(',', ';').split(';')]\n",
    "    for category in categories_list:\n",
    "        if '(' in category and ')' in category:\n",
    "            subcategories = [subcat.strip() for subcat in category.split() if subcat[0].isdigit()]\n",
    "            for subcategory in subcategories:\n",
    "                tags.add(subcategory)\n",
    "        else:\n",
    "            tags.add(category)\n",
    "tags.discard('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16G20', '47G20', '62M02', '00Bxx', 'F.2.2', 'I.3.0', 'I.5.2', 'G.2.6', '68T01', '35-XX', '90C05', '46M20', '62M20', '68T10', '74S30', '30C40', '94A34', '06A15', 'I.1.3', '97P30', 'q-fin.GN', 'I.2.1 Applications Expert Systems', '93E35', '65N12', '37M10', 'cond-mat.other', '65L07', '46N30', 'I.2.8', '65L05', '62M10', '92C50', 'cs.GR', '82B20', '74S05', '62P12', 'I.7.1', '65R30', '65C30', 'I.4.6', '62-07l', 'math.GT', '65D05', '35K55', '68P15', '91A80', '91B84', 'I.6', '68P20', 'math.NT', '68W25', 'I.6.8', 'cs.AR', 'q-bio.GN', 'math-ph', 'math.OC', '03D10', 'cs.NA', 'Artificial intelligence', '62G05', 'G.3', 'math.CO', '47B34', '53Z50', 'E.4', '47B32', 'H.4.2', 'I.2.7', '68T07', 'astro-ph.EP', '60G15', 'cs.FL', 'math.AC', '76T99', 'C.4', '92E10', 'I.5.4.m', '68W99', 'G.2', '14M25', 'cond-mat.str-el', '03B70', '92B20', 'H.2', '41A46', 'cs.SC', '90-08', 'I.3.6', 'F.1.3', '62P30', '68W40', 'stat.AP', '62D20', '93B35', 'cs.MS', '91F20', 'K.4.2', '62D05', '90C35', 'math.CT', '49N45', 'stat.ML', 'C.2.4', '68Wxx', '41A10', 'I.2.11', 'nlin.PS', 'q-bio.MN', '68U20', 'I.5', '62R07', '68U99', '37N35', 'I.2.0.b', '65C50', '74A40', 'J.6', 'stat.CO', '46N10', '37G05', 'K.4.4', '90-05', '2010', 'physics.geo-ph', '60G35', 'I.4.3', '68T50', '91A60', '65F22', 'D.2.5', 'adap-org', '68W05', '91G70', '60H05', 'nlin.CD', 'F.2.0', '15A60', 'astro-ph', '57Z25', '68N20', '05C20', 'I.2.10.f', '62A09', '68T05', '65M06', 'stat.OT', '68-04', 'org', '35CXX', 'math.MP', '62L10', '68W10', '49Q10', '92D20', '90C08', '62H25', '60L20', '62E17', 'physics.ins-det', '93Cxx', '68W15', 'I.4.m', '11J71', 'math.GN', '68: computer science', '93B30', '47N10', 'physics.ed-ph', 'G.2.3', 'math.RA', 'math.DG', 'D.1.3', 'C.3', '60J25', '90-01', '65K10', 'G.1.2', 'cs.RO', 'physics.plasm-ph', '68N30', 'math.RT', 'math.AP', 'H.5.1', '93', 'cs.DL', '76D07', '35R02', 'physics.soc-ph', 'cs.ET', '30E05', '60H30', '62H35', '68U05', '92C55', 'I.5.5', '91B10', '60G55', '94-02', 'math.ST', '62P10', '74Q15', '62G20', '65M22', 'I.5.4.b', '62P35', 'G.2.2', '54E05', '43A32', '93E03', 'F.2.4', '90-10', 'K.3.2', '68T30', '90C25', '68T05 91E40', 'physics.comp-ph', '90-06', '60G10', 'K.3.m', 'E.0', '05C62', 'cs.DC', '90C17', 'E.2', 'B.7.2', 'nucl-ex', '68Q55', '53B20', '74B05', 'H.5', 'H.1.1', 'J.1', '86-04', 'I.4.0', '62R40', 'I.3.7', 'I.6.3', 'q-fin.ST', 'Computing methodologies for image processing', '91A12', 'q-bio.OT', 'H.1.2', '37N30', 'physics.data-an', 'I.2.3', '35J47', 'math.GR', 'cs.SE', '62F12', '94A12', 'I.3', 'G.2.1', '68Q25', 'G.1', '62-02', 'C.2', '68T04', '06A06', '62M05', '94A17', 'cond-mat.stat-mech', '41A65', '65N21', 'G.3.7', '41A52', 'math.IT', '78', 'cs.PF', '49J55', '68T05', '00', '62G08', '35P15', '91G80', '60K35', 'q-fin.RM', '91-10', '68Q42', '62E10', '62-07', 'cs.CV', '62H17', '65C10', '35Q74', 'q-bio.QM', '65F50', 'I.2.4', '62H22', '62M15', 'B.4.2', '58D10', 'H.3', '92-XX', 'q-fin.PM', '62C05', 'H.5.0', '82C32', '26A33', 'G.1.4', 'astro-ph.GA', '90C10', '81Pxx', 'G.1.3', 'J.7', 'E.5', '34H05', 'C.4.4', '68-XX', 'J.2.', 'math.PR', 'q-fin.CP', '37H99', '62H15', 'J.2.4', '03G10', 'cs.AI', '05C60', 'q-bio.NC', '14M07', 'cs.MM', '92B25 92F99', '46E22', '97R40', '65D17', 'cs.DB', 'hep-ex', '68T09', '44A12', '65C60', '60G09', '05B45', '62J02', '60', 'math.CV', '74L05', '54F45', '60L10', 'physics.space-ph', '15B48', '05C85', 'H.5.2', 'q-bio.BM', '47A60', '97C30', 'math.AG', '68T01', 'G.1.8', '92B20', '62F35', '46M40', 'astro-ph.SR', 'H.2.0', '62G32', 'cs.SY', '68R10', '62J10', '65J22', 'G.4', 'cs.LG', 'C.2.2', '68W50', 'cs.CY', '62M09', '68W27', '68T37', '86-08', '35K08', '60G40', 'F.2', '65N99', '65D10', '65M55', '15A06', '60J05', '93B50', '68T27', 'G.1.6', '68T07', '93C41', '62', '90C20', 'nucl-th', 'D.3.2', 'physics.bio-ph', '60J27', 'H.3.4', '35J20', 'This paper tells us how human can be identified by their Gait cycle\\n  using any simple camera', '65Yxx', '62G35', 'physics.med-ph', 'q-fin.TR', '74L10', '2020: 49N45', '90B18', 'I.2.7.g', '90Cxx', '46E30', '62H30', 'physics.app-ph', '68P99', '62J05', '74Pxx', '00B25', '03B65', '86A10', 'q-fin.MF', 'math.HO', '68Txx', 'cs.LO', '65N06', '68Q32', '62H99', '35J50', '62B86', 'I.2.1', 'J.3.1', 'H.2.7', '90B22', '49M41', '68U10', '91C20', 'cond-mat', 'cond-mat.soft', '90C90', '35B50', 'F.3.1', '49-11', 'econ.GN', '90C30', 'physics.flu-dyn', '68T42', 'cs.SD', '65Zxx', 'K.3.8', '14T10', '68U10', '55U10', '93E20', 'I.1.2', 'H.2.4', '10010147.10010257.10010258.10010259.10010263', '65M20', '62-09', '62P10', '90C59', '49N10', '03B52', '90C22', '51M20', 'cs.SI', 'E.1', 'F.m', '62M40', 'hep-th', '65M12', '51N05', '37E25', '33E10', 'I.2.m', '58J35', 'cs.IR', '68U15', '58J90', 'eess.SY', 'D.2.8', 'q-fin.EC', '68U01', '68W01', 'stat.ME', '94', '49-06', '60D05', 'hep-ph', '49M29', 'I.4.2', '49J20', '15A69', '62F10', 'eess.SP', 'math.NA', 'I.2.9', '15A63', '35J15', '60H99', '65F30', '62F15', '06B99', '68-01', '05A16', '60J22', '60J10', '6006', '57-08', '92C55', 'q-fin.PR', 'I.5.4', '35Q84', '62J99', '65D18', 'I.6.5', 'F.4.1', 'cs.CC', 'q-bio.PE', '91E30', 'I.5.0', '70-08', '35Q79', '41A05', '14R10', '54H30', '94A15', '62-08', '91C99', 'math.FA', 'G.1.0', 'cond-mat.dis-nn', '65D15', '37N99', 'cond-mat.mes-hall', '28A33', '62J07', '76M10', '14F05', '14L24', '11Z05', '41A63', '62J12', 'H.4.0', 'I.4.m I.2.7', '65R32', '37M05', 'cond-mat.mtrl-sci', '93E10', 'astro-ph.CO', 'I.4.4', '62G99', '65Dxx', '03-04', 'physics.class-ph', '34C20', 'J.2.5', 'I.2.5', 'I.3.4', 'H.4.m', '34A99', 'D.2.0', '62H12', 'I.3.8', '05C99', '91A20', '90C27', 'astro-ph.IM', '60C05', '65D19', '90C26', '68R99', 'H.3.3', '11Y16', '00-02', 'math.CA', 'D.3.4', 'B.5.1', '90C40', '62F03', 'G.3.11', 'cs.GT', 'I.4', 'q-bio.CB', '62-XX', 'q-bio.TO', 'I.1.5', 'I.5.2.b', '05C21', '80A30', '35J08', '42-08', '05C70', '92B99', '62G07', '90C46', 'I.2', '37Nxx', 'J.m', '68', '93C85', '55U99', 'cs.CE', '91B08', '60G99', 'gr-qc', 'cs.OH', '68M25', 'math.DS', 'D.2.2', '60-08', '68-06', 'C.1.3', '65Z05', 'K.4', 'J.4', 'I.4.1', '53A20', 'K.5.2', '91-08', 'J.2', '68U35', 'J.5', '78M32', 'math.LO', 'F.4.2', 'C.2.1', 'I.1.4', '65M99', '62G86', 'D.2.11', '65F55', '35A15', '93E12', '68P30', '37M25', 'A.1', '15A83', 'cs.CR', '93B15', 'nlin.AO', '35A18', '76S05', '52C25', 'econ.TH', '68T45', 'eess.IV', '62C10', 'I.5.1', '54E40', '14Q15', '68T40', 'I.5.3', 'I.2.10', 'physics.acc-ph', 'cs.HC', 'D.4.6', '62M45', 'I.2.0', '26B40', 'cs.DM', '42B35', '60J20', 'I.4.5', '62R01', '68Q87', '62H20', '65T50', '60G60', '42C40', 'physics.optics', '49L20', 'physics.ao-ph', '49N30', 'cs.OS', '55R35', '68T99', 'H.0', 'astro-ph.HE', 'B.m', '62F40', 'H.5.5', '60E05', '14J60', 'cs.CG', 'nlin.CG', 'physics.pop-ph', '62P15', 'eess.AS', '65K05', '62J10', 'H.4', '65C20', 'I.4.8', '35K57', '35K15', '49M37', 'cs.DS', '47G30', 'F.1.1', 'stat.TH', '49', '68T20', 'ams.org', 'H.2.8', 'J.0', 'cs.MA', '91E40', '15A29', '47N30', '62B10', '62h30', '62P99', '68T45 68T07', 'I5.3', 'I.0', 'hep-lat', '91Bxx', '90', 'I.3.3', '92', 'cs.CL', '46M15', 'I.3.5', '05C81', 'C.2.6', 'I.7', 'I.6.6', 'B.7.1', '90B99', '62F25', 'cs.NI', '62G09', '90C06', 'I.4.9', 'math.SP', 'J.3', 'math.AT', '65S05', 'I.7.5', 'E.3', '62C99', 'D.2', '65C05', '62F07', 'cs.NE', '58E30', 'F.2.1', 'cs.PL', '97N80', 'H.3.1', '94A08', '05C50', 'I.6.4', '91D30', 'quant-ph', '05C80', '49Q22', 'econ.EM', 'Computer science applications- 97R60 Computer graphics', '49M15', 'math.OA', 'physics.chem-ph', '65F15', '60-06', '35Q68', '6804', '65T60', 'I.2.2', 'math.MG', '53A04', '91A06', '55N99', '14J26', '53A17', '94C15', '41A30', '14M15', 'I.2.6', '60B20', '94A60', '47A58', 'I.2.4.j', 'I.4.7', '68Tx', '65Kxx', '62G10', 'cs.IT', '91B16', '51K05', '55N31', 'I.4.10']\n"
     ]
    }
   ],
   "source": [
    "tags_list = []\n",
    "for tag in tags:\n",
    "    tag = tag.replace('(Primary)', '')\n",
    "    tag = tag.replace('Primary', '')\n",
    "    tag = tag.replace('(Secondary)', '')\n",
    "    tag = tag.replace('(secondary)', '')\n",
    "    tag = tag.replace('secondary', '')\n",
    "    tag = tag.replace('Secondary', '')\n",
    "    tag = tag.replace('and ', '')\n",
    "    tags_list.append(tag.strip())\n",
    "print(tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty lists for each classification\n",
    "msc = set()\n",
    "ccs = set()\n",
    "arxiv = set()\n",
    "misc = set()\n",
    "\n",
    "for tag in tags_list:\n",
    "    if re.match(r'\\d{2}[A-Z]\\d{2}|\\d{2}[A-Z]-xx|\\d{2}\\w{2,}', tag):\n",
    "        msc.add(tag)\n",
    "    elif re.match(r'\\d{2}-\\d{2}|\\d{2}-xx|\\d{2}-XX', tag):\n",
    "        msc.add(tag)\n",
    "    elif re.match(r'\\d{2}', tag):\n",
    "        msc.add(tag)\n",
    "    elif re.match(r'[A-Z]\\.\\d\\.\\d', tag):\n",
    "        ccs.add(tag)\n",
    "    elif re.match(r'[A-Z]\\.\\d', tag):\n",
    "        ccs.add(tag)\n",
    "    elif re.match(r'[A-Z]\\d\\.\\d', tag):\n",
    "        ccs.add(tag)\n",
    "    elif re.match(r'\\w+\\.\\w+', tag):\n",
    "        arxiv.add(tag)\n",
    "    elif re.match(r'\\w+-\\w+\\.\\w+-\\w+', tag):\n",
    "        arxiv.add(tag)\n",
    "    elif re.match(r'\\w+-\\w+\\.\\w+', tag):\n",
    "        arxiv.add(tag)\n",
    "    elif re.match(r'\\w+-\\w+', tag):\n",
    "        arxiv.add(tag)\n",
    "    else:\n",
    "        misc.add(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSC: 453\n",
      "CCS: 162\n",
      "ArXiv: 149\n",
      "Misc: 5\n"
     ]
    }
   ],
   "source": [
    "print(f'MSC: {len(msc)}\\nCCS: {len(ccs)}\\nArXiv: {len(arxiv)}\\nMisc: {len(misc)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents of misc:**\n",
    "- Artificial intelligence': corresponds to 68Txx\n",
    "- Computer science applications- 97R60 Computer graphics': corresponds to 97R60\n",
    "- Computing methodologies for image processing': corresponds to 68U10\n",
    "- This paper tells us how human can be identified by their Gait cycle\\n  using any simple camera': dropped\n",
    "- org: dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc.add('97R60')\n",
    "del misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc_cleaned = pd.DataFrame(list(msc), columns=['msc'])\n",
    "ccs_cleaned = pd.DataFrame(list(ccs), columns=['ccs'])\n",
    "arxiv_cleaned = pd.DataFrame(list(arxiv), columns=['arxiv'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Descriptions for Each Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc_html = r'C:\\Users\\User\\Desktop\\ml_paper_recommender_system\\paper-recommender\\Classification Codes Data\\MSC Classification Codes.html'\n",
    "\n",
    "# Parse MSC Classification Codes html file\n",
    "with open(msc_html) as fp:\n",
    "    msc_soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "# Extract MSC Classification Codes\n",
    "msc_tree = [element.text for element in msc_soup.find_all('li')]\n",
    "\n",
    "# Define Dictionary for MSC Classification Codes where the key is the main class and the value is a list of sub-classes\n",
    "msc_classes = {}\n",
    "\n",
    "# Populate the dictionary\n",
    "for cls in msc_tree:\n",
    "    if re.match(r'^\\d\\d-xx:', cls):\n",
    "        msc_classes[cls.split('\\n')[0]] = []\n",
    "\n",
    "for element in msc_tree:\n",
    "    for cls in msc_classes.keys():\n",
    "        if cls[0:2] == element[0:2]:\n",
    "            msc_classes[cls].append(element)\n",
    "\n",
    "for cls in msc_classes.keys():\n",
    "    msc_classes[cls].pop(0)\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "msc_df = pd.DataFrame(msc_classes.items(),columns=['class','sub_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00-01', ' Instructional exposition (textbooks, tutorial papers, etc.)']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msc_df['sub_classes'].values[0][0].split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_string</th>\n",
       "      <th>sub_class</th>\n",
       "      <th>sub_class_string</th>\n",
       "      <th>sub_sub_class</th>\n",
       "      <th>sub_sub_class_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  class_string  sub_class  sub_class_string  sub_sub_class   \n",
       "0    0.0           0.0        0.0               0.0            0.0  \\\n",
       "1    0.0           0.0        0.0               0.0            0.0   \n",
       "2    0.0           0.0        0.0               0.0            0.0   \n",
       "3    0.0           0.0        0.0               0.0            0.0   \n",
       "4    0.0           0.0        0.0               0.0            0.0   \n",
       "5    0.0           0.0        0.0               0.0            0.0   \n",
       "\n",
       "   sub_sub_class_string  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "5                   0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = [np.zeros(6) for i in range(6)]\n",
    "columns = ['class', 'class_string', 'sub_class', 'sub_class_string', 'sub_sub_class', 'sub_sub_class_string']\n",
    "msc_index = pd.DataFrame(dummy, columns=columns)\n",
    "msc_index.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11Gxx: Arithmetic algebraic geometry (Diophantine geometry)\n",
      "11G05: Elliptic curves over global fields\n",
      "11G07: Elliptic curves over local fields\n",
      "11G09: Drinfeld modules; higher-dimensional motives, etc.\n",
      "11G10: Abelian varieties of dimension $\\gtr 1$\n",
      "11G15: Complex multiplication and moduli of abelian varieties\n",
      "11G16: Elliptic and modular units\n",
      "11G18: Arithmetic aspects of modular and Shimura varieties\n",
      "11G20: Curves over finite and local fields\n",
      "11G25: Varieties over finite and local fields\n",
      "11G30: Curves of arbitrary genus or genus $\\ne 1$ over global fields\n",
      "11G35: Varieties over global fields\n",
      "11G40: $L$-functions of varieties over global fields; Birch-Swinnerton-Dyer conjecture\n",
      "11G45: Geometric class field theory\n",
      "11G50: Heights\n",
      "11G55: Polylogarithms and relations with $K$-theory\n",
      "11G99: None of the above, but in this section\n",
      "11G30: Curves of arbitrary genus or genus $\\ne 1$ over global fields\n"
     ]
    }
   ],
   "source": [
    "cls = []\n",
    "cls_str = []\n",
    "sub_cls = []\n",
    "sub_cls_str = []\n",
    "sub_sub_cls = []\n",
    "sub_sub_cls_str = []\n",
    "for idx, sub_class in enumerate(msc_df['sub_classes'].values):\n",
    "    # Class\n",
    "    # \\d\\d-\\d\\d\n",
    "    ## Sub-Class\n",
    "    ## Identifier: \\d\\d\\w\\X\\X\n",
    "    ### Tag: \\d\\d\\w\\w\\w\n",
    "    ### Sub-Sub-Class\n",
    "    ### \\d\\d\\w\\d\\d\n",
    "    #print(sub_class[idx].split(':')[0])\n",
    "    for sub_sub in sub_class:\n",
    "        if re.match(r'\\d\\d-\\d\\d', sub_sub):\n",
    "            cls.append(sub_sub.split(':')[0])\n",
    "            cls_str.append(sub_sub.split(':')[1].strip())\n",
    "        if re.match(r'\\d\\d\\w\\w\\w', sub_sub):\n",
    "            if r'\\n' in sub_sub:\n",
    "                # can't figure out how to split at '\\n'\n",
    "                #sub_sub = sub_sub.split('\\n')[0]\n",
    "                print(sub_sub)\n",
    "                #print(sub_sub.split(r'\\n')[0])\n",
    "            sub_cls.append(sub_sub.split(':')[0])\n",
    "            sub_cls_str.append(sub_sub.split(':')[1].strip())\n",
    "        if re.match(r'\\d\\d-\\d\\dX', sub_sub):\n",
    "            cls.append(sub_sub)\n",
    "        if re.match(r'\\d\\d-\\d\\dX', sub_sub):\n",
    "            cls.append(sub_sub)\n",
    "        if re.match(r'\\d\\d-\\d\\dX', sub_sub):\n",
    "            cls.append(sub_sub)            \n",
    "#sub_cls_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['00-02', ' Research exposition (monographs, survey articles)']),\n",
       "       list(['01-08', ' Computational methods']),\n",
       "       list(['03-06', ' Proceedings, conferences, collections, etc.\\n03A05', ' Philosophical and critical']),\n",
       "       list(['05-06', ' Proceedings, conferences, collections, etc.']),\n",
       "       list(['06-06', ' Proceedings, conferences, collections, etc.']),\n",
       "       list(['08-06', ' Proceedings, conferences, collections, etc.'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msc_index['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, subclass in enumerate(msc_df['sub_classes']):\n",
    "    for idx, sub in enumerate(subclass):\n",
    "        if re.match(r'\\d+\\d+[A-Z]xx', sub):\n",
    "            msc_df['sub_classes'][i][idx] = sub.split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, subclass in enumerate(msc_df['sub_classes']):\n",
    "    curr_cls = msc_df['class'][i]\n",
    "    for idx, sub in enumerate(subclass):\n",
    "        msc_df['sub_classes'][i][idx] = curr_cls + ' ' + msc_df['sub_classes'][i][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, tag in enumerate(msc_cleaned['msc']):\n",
    "    if ':' in tag:\n",
    "        msc_cleaned['msc'][idx] = tag.split(':')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc_cleaned['description'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tag in enumerate(msc_cleaned['msc']):\n",
    "    for j, subclass in enumerate(msc_df['sub_classes']):\n",
    "        for k, cls in enumerate(subclass):\n",
    "            if tag in cls:\n",
    "                msc_cleaned['description'][i] = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_msc = []\n",
    "for idx, description in enumerate(msc_cleaned['description']):\n",
    "    if description is None:\n",
    "        missing_msc.append(msc_cleaned['msc'][idx])\n",
    "print(f'Status:\\n{len(missing_msc)} out of {len(msc_cleaned)} tags are missing a description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Description from MSC Classification Codes 2020\n",
    "reader = PyPDF2.PdfReader(r'C:\\Users\\User\\Desktop\\ml_paper_recommender_system\\paper-recommender\\Classification Codes Data\\msc2020.pdf')\n",
    "missing_corpus = []\n",
    "for idx, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    for idx, code in enumerate(missing_msc):\n",
    "        if code in text:\n",
    "            missing_corpus.append(text)\n",
    "            # print(f'Page {idx+1}: {code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, text in enumerate(missing_corpus):\n",
    "    missing_corpus[idx] = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_descriptions = set()\n",
    "for code in missing_msc:\n",
    "    for idx, text in enumerate(missing_corpus):\n",
    "        for line in text:\n",
    "            if code in line:\n",
    "                desc = f'{code}: {line}'\n",
    "                missing_descriptions.add(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspected manually because data quality right?\n",
    "missing_descriptions = [\n",
    " '60B20: 60B20 Random matrices (probabilistic aspects)',\n",
    " '62H22: 62H22 Probabilistic graphical models',\n",
    " '97P30: 97P30 Systems, databases (educational aspects)',\n",
    " '05C81: 05C81 Random walks on graphs',\n",
    " '62B86: 62B86 Statistical aspects of fuzziness, sufficiency, and information',\n",
    " '68T42: 68T42 Agent technology and artificial intelligence',\n",
    " '97N80: 97N80 Mathematical software, computer programs (educational aspects)',\n",
    " '60L10: 60L10 Signatures and data streams',\n",
    " '35Q68: 35Q68 PDEs in connection with computer science',\n",
    " '68T07: 68T07 Artificial neural networks and deep learning',\n",
    " '60L20: 60L20 Rough paths',\n",
    " '62-08: 62-08 Computational methods for problems pertaining to statistics',\n",
    " '35Q79: 35Q79 PDEs in connection with classical thermodynamics and heat transfer',\n",
    " '15B48: 15B48 Positive matrices and their generalizations; cones of matrices',\n",
    " '68W50: 68W50 Evolutionary algorithms, genetic algorithms (computational aspects)',\n",
    " '62-XX: 62-XX Statistics',\n",
    " '65Zxx: 65Zxx Applications to the sciences',\n",
    " '62G86: 62G86 Nonparametric inference and fuzziness',\n",
    " '62R40: 62R40 Topological data analysis',\n",
    " '05C21: 05C21 Flows in graphs',\n",
    " \"35J08: 35J08 Green's functions for elliptic equations\",\n",
    " '91-10: 91-10 Mathematical modeling or simulation for problems pertaining to game theory, economics, and Finance',\n",
    " '90-05: 90-05 Experimental work for problems pertaining to operations research and mathematical programming',\n",
    " '68W27: 68W27 Online algorithms; streaming algorithms',\n",
    " '14T10: 14T10 Foundations of tropical geometry and relations with algebra',\n",
    " '62D20: 62D20 Causal inference from observational studies',\n",
    " '49Q22: 49Q22 Optimal transportation',\n",
    " '35R02: 35R02 PDEs on graphs and networks (ramified or polygonal spaces)',\n",
    " '57-08: 57-08 Computational methods for problems pertaining to manifolds and cell complexes',\n",
    " '65F55: 65F55 Numerical methods for low-rank matrix approximation; matrix compression',\n",
    " '90C17: 90C17 Robustness in mathematical programming',\n",
    " '53Z50: 53Z50 Applications of differential geometry to data and computer science',\n",
    " '35J47: 35J47 Second-order elliptic systems',\n",
    " '62R07: 62R07 Statistical aspects of big data and data science',\n",
    " '15A83: 15A83 Matrix completion problems',\n",
    " '91G80: 91G80 Financial applications of other theories',\n",
    " '54H30: 54H30 Applications of general topology to computer science (e.g., digital topology, image processing)',\n",
    " '35K08: 35K08 Heat kernel',\n",
    " '90-10: 90-10 Mathematical modeling or simulation for problems pertaining to operations research and mathematical programming',\n",
    " '78M32: 78M32 Neural and heuristic methods applied to problems in optics and electromagnetic theory',\n",
    " '62A09: 62A09 Graphical methods in statistics',\n",
    " '35Q74: 35Q74 PDEs in connection with mechanics of deformable solids',\n",
    " '55N31: 55N31 Persistent homology and applications, topological data analysis',\n",
    " '68-XX: 68-XX Computer science',\n",
    " '65D19: 65D19 Computational issues in computer and robotic vision',\n",
    " '68M25: 68M25 Computer security',\n",
    " '62-08: 62-08 Computational methods for problems pertaining to statistics',\n",
    " '92-XX: 92-XX Biology and other natural sciences',\n",
    " '35-XX: 35-XX Partial differential equations',\n",
    " '68Q87: 68Q87 Probability in computer science (algorithm analysis, random structures, phase transitions, etc.)',\n",
    " '60B20: 15B52 Random matrices (algebraic aspects) fFor probabilistic aspects, see 60B20 g',\n",
    " '91G70: 91G70 Statistical methods; risk measures [See also 62P05, 62P20]',\n",
    " '62R01: 62R01 Algebraic statistics',\n",
    " '49Q22: 35Q49 Transport equations fFor calculus of variations and optimal control, see 49Q22; for Fluid mechanics, see',\n",
    " '60B20: 60B20 Random matrices (probabilistic aspects)',\n",
    " '49M41: 49M41 PDE constrained optimization (numerical aspects)',\n",
    " '57Z25: 57Z25 Relations of manifolds and cell complexes with computer and data science',\n",
    " '49-11: 49-11 Research data for problems pertaining to calculus of variations and optimal control',\n",
    " '35Q84: 35Q84 Fokker-Planck equations',\n",
    " '42-08: 42-08 Computational methods for problems pertaining to harmonic analysis on Euclidean spaces',\n",
    " '68T09: 68T09 Computational aspects of data analysis and big data',\n",
    " '65M22: 65M22 Numerical solution of discretized equations for initial value and initial-boundary value problems involving ']\n",
    "\n",
    "for idx, desc in enumerate(missing_descriptions):\n",
    "    missing_descriptions[idx] = desc.split(':')\n",
    "\n",
    "\n",
    "for idx, description in enumerate(missing_descriptions):\n",
    "    m, d = missing_descriptions[idx]\n",
    "    for idx2, code in enumerate(msc_cleaned['msc']):\n",
    "        if msc_cleaned['msc'][idx2] == m:\n",
    "            msc_cleaned['description'][idx2] = d.strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and add misplaced string back to ACM codes\n",
    "print(f'Before: {len(ccs_cleaned)}')\n",
    "acm_misplaced_string = '10010147.10010257.10010258.10010259.10010263'.split('.')\n",
    "for str in acm_misplaced_string:\n",
    "    ccs_cleaned.loc[-1] = str\n",
    "    ccs_cleaned.index = ccs_cleaned.index + 1\n",
    "    ccs_cleaned = ccs_cleaned.sort_index()\n",
    "print(f'After: {len(ccs_cleaned)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem = msc_cleaned[msc_cleaned['description'].isnull()]['msc'].values\n",
    "rem = ['60-06', '68T05', '91E40', '92B25', '92F99', '35CXX', '97R60', '68-04',\n",
    "       '68T45', '68T07', '62h30', '97R40', '62-07', '68T04']\n",
    "found_rem = []\n",
    "for r in rem:\n",
    "    desc = msc_cleaned['description'][idx]\n",
    "    if r in msc_cleaned['msc'].values:\n",
    "        print(f'Found: {r}')\n",
    "        desc = msc_cleaned[msc_cleaned['msc'] == r]['description'].values[0]\n",
    "        print(f'Description: {desc}')\n",
    "        if desc is not None:\n",
    "            found_rem.append(r)\n",
    "    else:\n",
    "        print(f'Not found: {r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem = set(rem) - set(found_rem)\n",
    "rem = list(rem)\n",
    "rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Descriptions should have main class >> sub class >> sub sub class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't append before finishing TODO above\n",
    "missing_descriptions.append([['97R60', '97-XX Mathematics education'], \n",
    "                            ['92B25', '92-XX Biology and other natural sciences 92Bxx Mathematical biology in general 92B25 Biological rhythms and synchronization'],\n",
    "                            ['68T04', '68-XX Computer science 68Txx Artificial intelligence 68T05 Learning and adaptive systems in artificial intelligence'],\n",
    "                            ['97R40', '97-XX Mathematics education'],\n",
    "                            ['92F99', '92-XX Biology and other natural sciences 92Fxx Other natural sciences (mathematical treatment)'],\n",
    "                            ['62H30', '62-XX Statistics 62Hxx Multivariate analysis  62H30 Classification and discrimination; cluster analysis (statistical aspects); mixture models'],\n",
    "                            ['35CXX', '35Cxx Representations of solutions to partial differential equations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_descriptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
